import requests
import pandas as pd
from datetime import datetime, date
import os
import customtkinter as ctk
from tkinter import messagebox
import threading
from concurrent.futures import ThreadPoolExecutor
from openpyxl import load_workbook
from openpyxl.styles import Border, Side, Alignment, Font
import glob
import time
import retrying

# Set customtkinter appearance
ctk.set_appearance_mode("System")  # Options: "Light", "Dark", "System"
ctk.set_default_color_theme("blue")  # Options: "blue", "green", "dark-blue"

# Set the working directory to the script's directory
script_dir = os.path.dirname(os.path.abspath(__file__))
os.chdir(script_dir)

# GUI Class
class App:
    def __init__(self, root):
        self.root = root
        self.root.title("DefectDojo and Contrast Data Mapper")
        self.root.geometry("600x400")

        # Main frame
        self.main_frame = ctk.CTkFrame(self.root)
        self.main_frame.pack(pady=10, padx=10, fill="both", expand=True)

        # Start button
        self.start_button = ctk.CTkButton(
            self.main_frame, text="Start", command=self.start_script, width=200
        )
        self.start_button.pack(pady=10)

        # Loading label
        self.loading_label = ctk.CTkLabel(self.main_frame, text="")
        self.loading_label.pack(pady=5)

        # Progress bar
        self.progress = ctk.CTkProgressBar(self.main_frame, width=400)
        self.progress.set(0)
        self.progress.pack(pady=5)

        # Console log area
        self.log_text = ctk.CTkTextbox(self.main_frame, height=200, width=580, state="disabled")
        self.log_text.pack(pady=10, fill="both", expand=True)

    def log(self, message):
        self.log_text.configure(state="normal")
        self.log_text.insert("end", f"{datetime.now().strftime('%H:%M:%S')}: {message}\n")
        self.log_text.configure(state="disabled")
        self.log_text.see("end")

    def start_script(self):
        self.start_button.configure(state="disabled")
        self.loading_label.configure(text="Loading...")
        self.animate_loading()
        threading.Thread(target=self.run_script_thread, daemon=True).start()

    def animate_loading(self):
        def update_dots():
            if self.loading_label.cget("text").startswith("Loading"):
                dots = self.loading_label.cget("text")[7:]
                if dots == "...":
                    self.loading_label.configure(text="Loading")
                else:
                    self.loading_label.configure(text="Loading" + dots + ".")
                self.root.after(1000, update_dots)
        self.root.after(1000, update_dots)

    def clear_xlsx_files(self):
        self.log("Clearing existing .xlsx files...")
        for file in glob.glob(os.path.join(script_dir, "*.xlsx")):
            try:
                os.remove(file)
                self.log(f"Deleted {os.path.basename(file)}")
            except Exception as e:
                self.log(f"Error deleting {os.path.basename(file)}: {e}")
        self.progress.set(0.05)

    def run_script_thread(self):
        # Step 1: Clear existing .xlsx files
        self.clear_xlsx_files()

        # Step 2: Fetch app_id:id mappings from DefectDojo API
        self.log("Fetching DefectDojo app_id:id mappings...")
        self.fetch_defectdojo_mappings()
        self.progress.set(0.25)

        # Step 3: Fetch Contrast applications
        self.log("Fetching Contrast applications...")
        applications = self.fetch_contrast_applications()
        self.progress.set(0.45)

        # Step 4: Fetch traces
        self.log("Fetching Contrast traces...")
        self.fetch_contrast_traces(applications)
        self.progress.set(0.6)

        # Step 5: Remove duplicates from Traces.xlsx
        self.log("Removing duplicates from Traces.xlsx...")
        self.remove_duplicates_from_traces()
        self.progress.set(0.7)

        # Step 6: Match and generate Final.xlsx
        self.log("Matching traces with mappings, generating Final.xlsx...")
        self.generate_final_xlsx()
        self.progress.set(0.85)

        # Step 7: Create engagements in DefectDojo
        self.log("Creating engagements in DefectDojo...")
        self.create_defectdojo_engagements()
        self.progress.set(0.95)

        # Step 8: Clean up intermediate files
        self.log("Cleaning up intermediate files...")
        self.cleanup_intermediate_files()
        self.progress.set(1.0)

        # Finalize
        self.loading_label.configure(text="")
        self.start_button.configure(state="normal")
        self.log("Script execution completed.")
        self.root.after(
            0, lambda: messagebox.showinfo("Success", "Engagements created and intermediate files cleaned up. Final.xlsx retained.")
        )

    @retrying.retry(stop_max_attempt_number=3, wait_fixed=2000)
    def fetch_defectdojo_mappings(self):
        defectdojo_url = "https://demo.defectdojo.org/api/v2/tests/?engagement=72668"
        headers = {"Authorization": "Token jdndjdjjd"}  # Replace with actual token
        mappings = []

        try:
            response = requests.get(defectdojo_url, headers=headers, timeout=10)
            if response.status_code == 200:
                data = response.json()
                for test in data.get("results", []):
                    app_id = test.get("title", "")
                    defectdojo_id = test.get("description", "")
                    if app_id and defectdojo_id:  # Ensure both fields are non-empty
                        mappings.append({"app_id": str(app_id).strip(), "id": str(defectdojo_id).strip()})
                df = pd.DataFrame(mappings)
                df.to_excel(os.path.join(script_dir, "products.xlsx"), index=False)
                self.log(f"Mappings saved to products.xlsx ({len(mappings)} mappings)")
            else:
                self.log(f"Error fetching DefectDojo mappings: {response.status_code} - {response.text}")
        except Exception as e:
            self.log(f"Exception fetching DefectDojo mappings: {e}")
            raise

    @retrying.retry(stop_max_attempt_number=3, wait_fixed=2000)
    def fetch_contrast_applications(self):
        contrast_token = "dhdjdjdjdjrjrjrjdj=="  # Replace with actual token
        org_uuid = "gshdhdhd"  # Replace with actual Org UUID
        api_key = "hhjkkjdddjdkdk"  # Replace with actual API key

        headers = {
            "Authorization": contrast_token,
            "API-Key": api_key,
            "Accept": "application/json",
        }

        base_url = "https://contrast.crm.com/Contrast/api/ng/"
        url = f"{base_url}{org_uuid}/applications/filter"
        applications = []

        with requests.Session() as session:
            session.headers.update(headers)
            try:
                response = session.get(url, timeout=10)
                if response.status_code == 200:
                    data = response.json()
                    for app in data.get("applications", []):
                        applications.append(
                            {"name": app.get("name", ""), "app_id": app.get("app_id", "")}
                        )
                    df = pd.DataFrame(applications)
                    df.to_excel(os.path.join(script_dir, "Applications.xlsx"), index=False)
                    self.log(f"Applications saved to Applications.xlsx ({len(applications)} applications)")
                else:
                    self.log(f"Error fetching applications: {response.status_code} - {response.text}")
            except Exception as e:
                self.log(f"Exception fetching applications: {e}")
                raise

        return applications

    def fetch_contrast_traces(self, applications):
        contrast_token = "dhdjdjdjdjrjrjrjdj=="  # Replace with actual token
        org_uuid = "gshdhdhd"  # Replace with actual Org UUID
        api_key = "hhjkkjdddjdkdk"  # Replace with actual API key

        headers = {
            "Authorization": contrast_token,
            "API-Key": api_key,
            "Accept": "application/json",
        }

        base_url = "https://contrast.crm.com/Contrast/api/ng/"
        traces = []

        @retrying.retry(stop_max_attempt_number=3, wait_fixed=2000)
        def fetch_traces_for_app(app):
            app_id = app["app_id"]
            url = f"{base_url}{org_uuid}/traces/{app_id}/filter?limit=100&status=Reported"
            app_traces = []
            try:
                response = session.get(url, timeout=10)
                if response.status_code == 200:
                    data = response.json()
                    for trace in data.get("traces", []):
                        app_traces.append(
                            {
                                "name": app["name"],
                                "app_id": app_id,
                                "Trace ID": trace.get("uuid", ""),
                                "Severity": trace.get("severity", ""),
                                "Status": trace.get("status", ""),
                                "Rule": trace.get("rule_title", ""),
                                "Trace Title": trace.get("title", ""),
                            }
                        )
                else:
                    self.log(f"Error for App ID {app_id}: {response.status_code} - {response.text}")
            except Exception as e:
                self.log(f"Exception for App ID {app_id}: {e}")
                raise
            return app_traces

        with requests.Session() as session:
            session.headers.update(headers)
            with ThreadPoolExecutor(max_workers=10) as executor:
                results = list(executor.map(fetch_traces_for_app, applications))

        for result in results:
            traces.extend(result)

        df = pd.DataFrame(traces)
        df.to_excel(os.path.join(script_dir, "Traces.xlsx"), index=False)
        self.log(f"Traces saved to Traces.xlsx ({len(traces)} traces)")

    def remove_duplicates_from_traces(self):
        try:
            traces_df = pd.read_excel(os.path.join(script_dir, "Traces.xlsx"))
            initial_count = len(traces_df)
            traces_df = traces_df.drop_duplicates(subset=["Trace ID"], keep="first")
            final_count = len(traces_df)
            traces_df.to_excel(os.path.join(script_dir, "Traces.xlsx"), index=False)
            self.log(f"Removed {initial_count - final_count} duplicate traces. {final_count} traces remain in Traces.xlsx")
        except FileNotFoundError:
            self.log("Error: Traces.xlsx not found.")
        except Exception as e:
            self.log(f"Error removing duplicates: {e}")

    def generate_final_xlsx(self):
        try:
            products_df = pd.read_excel(os.path.join(script_dir, "products.xlsx"))
            traces_df = pd.read_excel(os.path.join(script_dir, "Traces.xlsx"))
        except FileNotFoundError as e:
            self.log(f"Error: {e}")
            return

        final_data = []
        # Create a dictionary for quick app_id to id lookup
        mapping_dict = dict(zip(products_df["app_id"], products_df["id"]))

        # Function to process a single trace
        def process_trace(trace_row):
            trace_app_id = trace_row["app_id"]
            defectdojo_id = mapping_dict.get(trace_app_id, 33)  # Default to 33 if no match
            return {
                "Trace ID": trace_row["Trace ID"],
                "Severity": trace_row["Severity"],
                "Status": trace_row["Status"],
                "Rule": trace_row["Rule"],
                "Trace Title": trace_row["Trace Title"],
                "name": trace_row["name"],
                "app_id": trace_row["app_id"],
                "id": defectdojo_id,
            }

        # Use ThreadPoolExecutor for parallel mapping
        with ThreadPoolExecutor(max_workers=10) as executor:
            final_data = list(executor.map(process_trace, [row for _, row in traces_df.iterrows()]))

        if not final_data:
            self.log("No traces found to process.")
            return

        columns = [
            "Trace ID",
            "Severity",
            "Status",
            "Rule",
            "Trace Title",
            "name",
            "app_id",
            "id",
        ]
        df = pd.DataFrame(final_data, columns=columns)
        excel_file = os.path.join(script_dir, "Final.xlsx")
        df.to_excel(excel_file, index=False)
        self.log(f"Final data saved to Final.xlsx ({len(final_data)} traces, {sum(1 for d in final_data if d['id'] != 33)} matched)")

        # Apply formatting
        wb = load_workbook(excel_file)
        ws = wb.active

        medium_border = Border(
            left=Side(style="medium"),
            right=Side(style="medium"),
            top=Side(style="medium"),
            bottom=Side(style="medium"),
        )
        thin_border = Border(
            left=Side(style="thin"),
            right=Side(style="thin"),
            top=Side(style="thin"),
            bottom=Side(style="thin"),
        )
        center_align = Alignment(horizontal="center", vertical="center")
        left_align = Alignment(horizontal="left", vertical="center")
        bold_font = Font(bold=True)

        for col_idx in range(1, ws.max_column + 1):
            cell = ws.cell(row=1, column=col_idx)
            cell.font = bold_font
            cell.alignment = center_align if col_idx > 1 else left_align
            cell.border = thin_border

        for row_idx in range(2, ws.max_row + 1):
            for col_idx in range(1, ws.max_column + 1):
                cell = ws.cell(row=row_idx, column=col_idx)
                cell.alignment = center_align if col_idx > 1 else left_align
                cell.border = thin_border

        wb.save(excel_file)
        self.log("Formatting applied to Final.xlsx")

    def create_engagement(self, trace_row, session, url, headers, current_date):
        payload = {
            "tags": ["contrast"],
            "target_start": current_date,
            "target_end": current_date,
            "status": "Not Started",
            "commit_hash": str(trace_row["Rule"]),
            "branch_tag": str(trace_row["Severity"]),
            "lead": 3,
            "product": int(trace_row["id"]),
            "name": str(trace_row["Trace ID"]),
        }
        try:
            response = session.post(url, json=payload, headers=headers, timeout=10)
            if response.status_code in (200, 201):
                self.log(f"Created engagement for Trace ID {trace_row['Trace ID']}")
            else:
                self.log(f"Error creating engagement for Trace ID {trace_row['Trace ID']}: {response.status_code} - {response.text}")
        except Exception as e:
            self.log(f"Exception creating engagement for Trace ID {trace_row['Trace ID']}: {e}")

    def create_defectdojo_engagements(self):
        try:
            final_df = pd.read_excel(os.path.join(script_dir, "Final.xlsx"))
        except FileNotFoundError:
            self.log("Error: Final.xlsx not found.")
            return

        defectdojo_url = "https://demo.defectdojo.org/api/v2/engagements"
        headers = {
            "Authorization": "Token jdndjdjjd",  # Replace with actual token
            "Content-Type": "application/json",
        }
        current_date = date.today().strftime("%Y-%m-%d")

        @retrying.retry(stop_max_attempt_number=3, wait_fixed=2000)
        def check_and_create_engagement(trace_row):
            trace_id = trace_row["Trace ID"]
            engagement_url = f"https://demo.defectdojo.org/api/v2/engagements?name={trace_id}"
            try:
                response = session.get(engagement_url, headers=headers, timeout=10)
                if response.status_code == 200:
                    data = response.json()
                    engagements = data.get("results", [])
                    if engagements:
                        for engagement in engagements:
                            if engagement.get("status") == "Completed":
                                # Create new engagement if existing one is Completed
                                self.create_engagement(trace_row, session, defectdojo_url, headers, current_date)
                            else:
                                self.log(f"Skipping engagement creation for Trace ID {trace_id}: Existing engagement status is {engagement.get('status')}")
                    else:
                        # No engagement found, create one
                        self.create_engagement(trace_row, session, defectdojo_url, headers, current_date)
                else:
                    self.log(f"Error checking engagement for Trace ID {trace_id}: {response.status_code} - {response.text}")
                # Delay to prevent overwhelming the slow API
                time.sleep(1)
            except Exception as e:
                self.log(f"Exception checking engagement for Trace ID {trace_id}: {e}")

        with requests.Session() as session:
            with ThreadPoolExecutor(max_workers=5) as executor:  # Reduced workers for slow API
                executor.map(check_and_create_engagement, [row for _, row in final_df.iterrows()])

    def cleanup_intermediate_files(self):
        self.log("Deleting intermediate files (Applications.xlsx, products.xlsx, Traces.xlsx)...")
        for file in ["Applications.xlsx", "products.xlsx", "Traces.xlsx"]:
            file_path = os.path.join(script_dir, file)
            try:
                if os.path.exists(file_path):
                    os.remove(file_path)
                    self.log(f"Deleted {file}")
                else:
                    self.log(f"{file} not found, skipping deletion")
            except Exception as e:
                self.log(f"Error deleting {file}: {e}")

if __name__ == "__main__":
    root = ctk.CTk()
    app = App(root)
    root.mainloop()