import requests
import pandas as pd
from bs4 import BeautifulSoup

BASE_URL = "https://jenkins.abf.com"
TOKEN = "jsjjdjdjd"   # your Jenkins token
JOB_PATH = "job/crm/job/develop{}/artifact/AllJiraIds/*view*/"
START_ID, END_ID = 1, 170
OUTPUT_FILE = "jenkins_jira_ids.xlsx"

session = requests.Session()
session.headers.update({
    "Authorization": f"Bearer {TOKEN}",
    "User-Agent": "JenkinsJiraFetcher/1.0"
})
session.verify = False   # set True if Jenkins has valid SSL

def build_url(version_id: int) -> str:
    return f"{BASE_URL}/{JOB_PATH.format(version_id)}"

def parse_lines(resp: requests.Response):
    ctype = resp.headers.get("Content-Type", "")
    if "text/plain" in ctype:
        return [ln.strip() for ln in resp.text.splitlines() if ln.strip()]
    soup = BeautifulSoup(resp.text, "html.parser")
    pre = soup.find("pre")
    text = pre.get_text("\n") if pre else soup.get_text("\n")
    return [ln.strip() for ln in text.splitlines() if ln.strip()]

rows = []
for vid in range(START_ID, END_ID + 1):
    url = build_url(vid)
    try:
        r = session.get(url, timeout=20)
        if r.status_code != 200:
            print(f"[skip] develop{vid}: {r.status_code}")
            continue
        lines = parse_lines(r)
        for ln in lines:
            rows.append({"Id": vid, "Jira id": ln})
        print(f"[ok] develop{vid}: {len(lines)} Jira IDs")
    except Exception as e:
        print(f"[error] develop{vid}: {e}")

df = pd.DataFrame(rows, columns=["Id", "Jira id"])
df.to_excel(OUTPUT_FILE, index=False)
print(f"\nDone. Saved {len(df)} rows into {OUTPUT_FILE}")