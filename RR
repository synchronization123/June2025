import requests
import pandas as pd
from bs4 import BeautifulSoup
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ==== CONFIG ====
BASE_URL = "https://jenkins.ac.com"  # <-- confirm host
USERNAME = "your_username"           # <-- your Jenkins username
TOKEN = "jsjjdjdjd"                  # <-- your Jenkins API token (password)
JOB_PATH = "job/crm/job/develop/{}/artifact/AllJiraIds/*view*/"
START_BUILD, END_BUILD = 1, 170
OUTPUT_FILE = "jenkins_jira_ids.xlsx"

# TLS verification:
#   1) If your company uses a custom root CA, point VERIFY to its .pem file path, e.g. r"C:\certs\corp-root.pem"
#   2) If your Jenkins uses a public CA, simply set VERIFY = True
VERIFY = True  # or e.g. r"C:\path\to\corp_root_ca.pem"

# ==== HTTP session with retries ====
session = requests.Session()
session.auth = (USERNAME, TOKEN)
session.headers.update({"User-Agent": "JenkinsJiraFetcher/1.1"})
session.verify = VERIFY

retry_policy = Retry(
    total=5, backoff_factor=0.5,
    status_forcelist=(429, 500, 502, 503, 504),
    allowed_methods=frozenset(["GET"])
)
session.mount("https://", HTTPAdapter(max_retries=retry_policy))

def build_url(build_no: int) -> str:
    # IMPORTANT: build number is a subpath: .../develop/{build}/artifact/...
    return f"{BASE_URL}/{JOB_PATH.format(build_no)}"

def parse_lines(resp: requests.Response):
    ctype = (resp.headers.get("Content-Type") or "").lower()
    if "text/plain" in ctype and "html" not in ctype:
        return [ln.strip() for ln in resp.text.splitlines() if ln.strip()]
    soup = BeautifulSoup(resp.text, "html.parser")
    pre = soup.find("pre")
    text = pre.get_text("\n") if pre else soup.get_text("\n")
    # Keep non-empty lines; if you want only Jira-like keys uncomment the regex filter below
    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
    # import re
    # lines = [ln for ln in lines if re.match(r"[A-Z][A-Z0-9_]+-\d+$", ln)]
    return lines

rows = []
for build in range(START_BUILD, END_BUILD + 1):
    url = build_url(build)
    try:
        r = session.get(url, timeout=25)
        if r.status_code == 404:
            print(f"[skip] build {build}: 404 Not Found")
            continue
        if r.status_code != 200:
            print(f"[skip] build {build}: HTTP {r.status_code}")
            continue
        lines = parse_lines(r)
        for ln in lines:
            rows.append({"Id": build, "Jira id": ln})
        print(f"[ok]   build {build}: {len(lines)} item(s)")
    except requests.exceptions.SSLError as e:
        print(f"[TLS]  build {build}: SSL error â€” set VERIFY=True or to your CA file. {e}")
        break
    except Exception as e:
        print(f"[err]  build {build}: {e}")

df = pd.DataFrame(rows, columns=["Id", "Jira id"])
df.to_excel(OUTPUT_FILE, index=False)
print(f"\nDone. Wrote {len(df)} rows to {OUTPUT_FILE}.")